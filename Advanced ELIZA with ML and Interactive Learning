import numpy as np
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, Any
from collections import defaultdict
import torch
from transformers import AutoTokenizer, AutoModel
from torch.nn import functional as F
import json
import time

class DualMemorySystem:
    def __init__(self, stm_capacity: int = 100, ltm_capacity: int = 1000):
        self.short_term_memory = []
        self.long_term_memory = []
        self.stm_capacity = stm_capacity
        self.ltm_capacity = ltm_capacity
        self.importance_threshold = 0.7
        self.consolidation_interval = 10  # Episodes before consolidation
        
    def add_memory(self, memory_item: Dict[str, Any]):
        # Add to short-term memory
        self.short_term_memory.append({
            **memory_item,
            'timestamp': time.time(),
            'access_count': 0,
            'importance_score': self._calculate_importance(memory_item)
        })
        
        # Manage capacity
        if len(self.short_term_memory) > self.stm_capacity:
            self._consolidate_memories()
    
    def _calculate_importance(self, memory_item: Dict) -> float:
        # Factors affecting importance:
        # - Emotional intensity (from sentiment)
        # - User feedback score
        # - Pattern success rate
        importance = 0.0
        
        if 'sentiment_score' in memory_item:
            importance += abs(memory_item['sentiment_score']) * 0.3
        
        if 'feedback_score' in memory_item:
            importance += memory_item['feedback_score'] * 0.4
        
        if 'pattern_success' in memory_item:
            importance += memory_item['pattern_success'] * 0.3
        
        return importance
    
    def _consolidate_memories(self):
        current_time = time.time()
        
        # Identify memories for consolidation
        to_consolidate = []
        remaining_stm = []
        
        for memory in self.short_term_memory:
            age = current_time - memory['timestamp']
            importance = memory['importance_score']
            
            if age > 3600 or importance > self.importance_threshold:  # 1 hour or important
                to_consolidate.append(memory)
            else:
                remaining_stm.append(memory)
        
        # Update short-term memory
        self.short_term_memory = remaining_stm
        
        # Add to long-term memory
        self.long_term_memory.extend(to_consolidate)
        
        # Maintain long-term memory capacity
        if len(self.long_term_memory) > self.ltm_capacity:
            # Remove least important memories
            self.long_term_memory.sort(key=lambda x: x['importance_score'])
            self.long_term_memory = self.long_term_memory[-self.ltm_capacity:]

class TransformerEncoder:
    def __init__(self, model_name: str = "bert-base-uncased"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()  # Set to evaluation mode
        
    def encode(self, text: str) -> torch.Tensor:
        with torch.no_grad():
            inputs = self.tokenizer(text, return_tensors="pt", 
                                  padding=True, truncation=True)
            outputs = self.model(**inputs)
            # Use [CLS] token embedding as sentence representation
            return outputs.last_hidden_state[:, 0, :]
    
    def compute_similarity(self, text1: str, text2: str) -> float:
        emb1 = self.encode(text1)
        emb2 = self.encode(text2)
        return F.cosine_similarity(emb1, emb2).item()

class SentimentAnalyzer:
    def __init__(self):
        self.encoder = TransformerEncoder()
        self.sentiment_keywords = {
            'positive': ['happy', 'good', 'great', 'wonderful', 'excellent'],
            'negative': ['sad', 'bad', 'terrible', 'awful', 'horrible'],
            'neutral': ['okay', 'fine', 'normal', 'average']
        }
    
    def analyze(self, text: str) -> Dict[str, float]:
        # Get transformer embeddings
        text_embedding = self.encoder.encode(text)
        
        # Compute keyword-based sentiment
        sentiment_scores = defaultdict(float)
        words = text.lower().split()
        
        for sentiment, keywords in self.sentiment_keywords.items():
            for keyword in keywords:
                if keyword in words:
                    sentiment_scores[sentiment] += 1.0
        
        # Normalize scores
        total = sum(sentiment_scores.values()) + 1e-6
        for sentiment in sentiment_scores:
            sentiment_scores[sentiment] /= total
        
        return dict(sentiment_scores)

class FeedbackSystem:
    def __init__(self):
        self.feedback_history = []
        self.pattern_feedback = defaultdict(list)
    
    def add_feedback(self, response_data: Dict[str, Any], 
                    feedback_score: float, feedback_text: Optional[str] = None):
        feedback_entry = {
            'timestamp': time.time(),
            'response_data': response_data,
            'feedback_score': feedback_score,
            'feedback_text': feedback_text
        }
        
        self.feedback_history.append(feedback_entry)
        
        if 'pattern_id' in response_data:
            self.pattern_feedback[response_data['pattern_id']].append(feedback_entry)
    
    def get_pattern_performance(self, pattern_id: str) -> Dict[str, float]:
        pattern_scores = self.pattern_feedback[pattern_id]
        if not pattern_scores:
            return {'average_score': 0.0, 'confidence': 0.0}
        
        scores = [entry['feedback_score'] for entry in pattern_scores]
        return {
            'average_score': sum(scores) / len(scores),
            'confidence': len(scores) / 100  # Confidence increases with more feedback
        }

class EnhancedScenarioGenerator:
    def __init__(self, encoder: TransformerEncoder):
        self.encoder = encoder
        self.scenario_templates = self._load_scenario_templates()
        self.context_variables = self._load_context_variables()
    
    def _load_scenario_templates(self) -> List[Dict]:
        # In practice, load from a JSON file
        return [
            {
                'name': 'emotional_support',
                'template': [
                    "I feel {emotion} because {situation}",
                    "It's affecting my {aspect}",
                    "I don't know what to {action}"
                ],
                'variables': {
                    'emotion': ['sad', 'anxious', 'overwhelmed', 'frustrated'],
                    'situation': ['of work', 'of my relationship', 'of my studies'],
                    'aspect': ['sleep', 'concentration', 'motivation'],
                    'action': ['do', 'think', 'decide']
                }
            },
            # Add more templates...
        ]
    
    def _load_context_variables(self) -> Dict:
        return {
            'locations': ['home', 'work', 'school'],
            'timeframes': ['today', 'this week', 'lately'],
            'people': ['friend', 'family member', 'colleague'],
            'emotions': ['happy', 'sad', 'angry', 'worried'],
            'activities': ['working', 'studying', 'relaxing']
        }
    
    def generate_scenario(self, difficulty: float = 0.5) -> Dict:
        # Select template based on difficulty
        template = random.choice(self.scenario_templates)
        
        # Generate scenario inputs
        inputs = []
        for template_text in template['template']:
            # Fill in variables
            for var_name, var_values in template['variables'].items():
                if '{' + var_name + '}' in template_text:
                    template_text = template_text.replace(
                        '{' + var_name + '}',
                        random.choice(var_values)
                    )
            inputs.append(template_text)
        
        # Generate expected patterns based on difficulty
        expected_patterns = self._generate_expected_patterns(inputs, difficulty)
        
        # Generate context requirements
        context_requirements = self._generate_context_requirements(difficulty)
        
        return {
            'name': template['name'],
            'inputs': inputs,
            'expected_patterns': expected_patterns,
            'context_requirements': context_requirements,
            'difficulty': difficulty
        }
    
    def _generate_expected_patterns(self, inputs: List[str], 
                                  difficulty: float) -> List[str]:
        patterns = []
        for input_text in inputs:
            # Generate appropriate response patterns based on input and difficulty
            if difficulty < 0.3:
                # Simple acknowledgment patterns
                patterns.append("I understand")
            elif difficulty < 0.7:
                # More complex empathy patterns
                patterns.append("I hear that you")
            else:
                # Advanced therapeutic patterns
                patterns.append("It seems like")
        return patterns
    
    def _generate_context_requirements(self, difficulty: float) -> Dict[str, float]:
        requirements = {}
        num_requirements = int(1 + difficulty * 4)  # 1-5 requirements based on difficulty
        
        possible_requirements = [
            'emotional_awareness',
            'topic_consistency',
            'empathy_shown',
            'solution_focus',
            'context_reference'
        ]
        
        selected = random.sample(possible_requirements, num_requirements)
        for req in selected:
            requirements[req] = random.uniform(0.5, 1.0) * difficulty
        
        return requirements

class MLEnhancedElizaAgent:
    def __init__(self):
        self.encoder = TransformerEncoder()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.memory_system = DualMemorySystem()
        self.feedback_system = FeedbackSystem()
        self.patterns = []
        self.learning_rate = 0.1
        
    def add_pattern(self, pattern: Dict[str, Any]):
        self.patterns.append({
            'id': str(len(self.patterns)),
            **pattern,
            'embedding': self.encoder.encode(pattern['template'])
        })
    
    def respond(self, input_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        # Analyze input
        sentiment = self.sentiment_analyzer.analyze(input_text)
        input_embedding = self.encoder.encode(input_text)
        
        # Find best matching pattern
        best_pattern = None
        best_score = -1
        
        for pattern in self.patterns:
            # Compute pattern match score
            embedding_similarity = F.cosine_similarity(
                input_embedding, 
                pattern['embedding']
            ).item()
            
            # Get pattern performance from feedback
            performance = self.feedback_system.get_pattern_performance(pattern['id'])
            
            # Combine scores
            total_score = (
                0.4 * embedding_similarity +
                0.3 * performance['average_score'] +
                0.3 * performance['confidence']
            )
            
            if total_score > best_score:
                best_score = total_score
                best_pattern = pattern
        
        if best_pattern is None:
            return self._generate_fallback_response(input_text, context)
        
        # Generate response using pattern
        response = self._generate_response(best_pattern, input_text, context)
        
        # Store in memory
        self.memory_system.add_memory({
            'input': input_text,
            'response': response,
            'pattern_id': best_pattern['id'],
            'sentiment_score': sentiment.get('positive', 0) - sentiment.get('negative', 0),
            'context': context
        })
        
        return {
            'text': response,
            'pattern_id': best_pattern['id'],
            'confidence': best_score
        }
    
    def _generate_response(self, pattern: Dict, input_text: str, 
                          context: Dict) -> str:
        # Implement sophisticated response generation logic
        pass
    
    def _generate_fallback_response(self, input_text: str, 
                                  context: Dict) -> Dict[str, Any]:
        # Generate fallback response using memory and context
        pass
    
    def receive_feedback(self, response_data: Dict[str, Any], 
                        feedback_score: float, feedback_text: Optional[str] = None):
        self.feedback_system.add_feedback(response_data, feedback_score, feedback_text)
        
        # Update pattern weights based on feedback
        if 'pattern_id' in response_data:
            pattern = next(p for p in self.patterns 
                         if p['id'] == response_data['pattern_id'])
            pattern['weight'] = pattern.get('weight', 1.0) * (
                1 + self.learning_rate * (feedback_score - 0.5)
            )

def create_enhanced_training_environment():
    encoder = TransformerEncoder()
    agent = MLEnhancedElizaAgent()
    scenario_generator = EnhancedScenarioGenerator(encoder)
    
    # Add sophisticated patterns
    agent.add_pattern({
        'template': "I feel {emotion} about {situation}",
        'responses': [
            "Tell me more about your {emotion} regarding {situation}",
            "How long have you been feeling {emotion} about {situation}?",
            "What aspects of {situation} make you feel most {emotion}?"
        ],
        'context_rules': {
            'emotional_awareness': 1.0,
            'topic_exploration': 0.8
        }
    })
    
    # Generate training scenarios
    scenarios = [
        scenario_generator.generate_scenario(difficulty)
        for difficulty in np.linspace(0.2, 0.9, 10)
    ]
    
    return agent, scenarios

def demonstrate_enhanced_training():
    agent, scenarios = create_enhanced_training_environment()
    
    print("Starting Enhanced Training...")
    
    for i, scenario in enumerate(scenarios):
        print(f"\nScenario {i+1} (Difficulty: {scenario['difficulty']:.2f})")
        
        for input_text in scenario['inputs']:
            response = agent.respond(input_text, {})
            print(f"\nUser: {input_text}")
            print(f"Agent: {response['text']}")
            
            # Simulate user feedback
            feedback_score = random.uniform(0.3, 1.0)  # Simulate varying feedback
            agent.receive_feedback(response, feedback_score)
            
            print(f"Feedback Score: {feedback_score:.2f}")

if __name__ == "__main__":
    demonstrate_enhanced_training()
